# Demo 3: Infrastructure & Cost Planning - GitHub Dashboard

**Purpose**: Build Terraform infrastructure for github-dashboard app with cost optimization focus, comparing 1K vs 10K users scenarios.

> **üìñ See the [GitHub Dashboard README](../packages/github-dashboard/README.md) for current implementation status and features.**  
> **üìä See [Performance Testing Results](./performance-testing.md) for load testing data and infrastructure sizing insights.**

## üéØ Goals & Requirements

### Primary Goals

- [x] Build Terraform that provisions infrastructure for github-dashboard app
- [x] Focus on cost optimization and realistic production planning
- [x] Compare 1,000 users/month vs 10,000 users/month scenarios
- [x] Use existing platform patterns from `agent_context/devops/`
- [x] Implement proper resource tagging for cost allocation
- [x] Validate with `terraform init`, `validate`, and `plan`
- [x] Use AWS Calculator for cost analysis
- [x] Document financial impact of infrastructure choices

## üìã Production Requirements & Cost Impact Analysis

### User Volume & Traffic Patterns

**Scenario 1: 1,000 Users/Month (Staging/Development)**

- **Concurrent Users**: 10-20 users
- **Peak Traffic**: 2x normal load during business hours
- **Data Growth**: 100 GitHub users, 20 dashboards, 500 activities
- **Cost Focus**: Development/testing costs

**Scenario 2: 10,000 Users/Month (Production)**

- **Concurrent Users**: 150-1,500 users (based on load testing)
- **Peak Traffic**: 5x normal load during releases/events
- **Data Growth**: 1,000 GitHub users, 100 dashboards, 5,000 activities
- **Cost Focus**: Production reliability and scaling

### Resource Categories & Consumption

| Resource Category     | 1K Users             | 10K Users               | Cost Driver                          |
| --------------------- | -------------------- | ----------------------- | ------------------------------------ |
| **Compute (CPU/RAM)** | 2 small instances    | 5-10 large instances    | Concurrent users, GraphQL processing |
| **Database Storage**  | 10GB PostgreSQL      | 100GB+ Aurora           | GitHub user data, activity logs      |
| **File Storage (S3)** | 1GB static assets    | 10GB+ exports/backups   | Dashboard exports, user uploads      |
| **CDN (CloudFront)**  | 100GB transfer       | 1TB+ transfer           | Global content delivery              |
| **Network (ALB)**     | Basic load balancing | High-availability setup | Traffic distribution                 |

### Unexpected Cost Scenarios

1. **GitHub API Rate Limits**: External API calls could hit rate limits, requiring multiple API keys
2. **Dashboard Export Feature**: Large CSV exports could consume significant S3 storage
3. **Real-time Updates**: WebSocket connections for live dashboard updates
4. **Data Retention**: Long-term storage of GitHub activity data
5. **Multi-tenant Isolation**: Separate resources per client for security

## üèóÔ∏è Terraform Infrastructure Design

### Core Infrastructure Components

```hcl
# EKS Cluster with cost-optimized node groups
resource "aws_eks_cluster" "github_dashboard" {
  name     = "github-dashboard-${var.environment}"
  role_arn = aws_iam_role.cluster.arn

  vpc_config {
    subnet_ids = var.private_subnet_ids
  }

  tags = local.common_tags
}

# Aurora PostgreSQL with serverless scaling
resource "aws_rds_cluster" "database" {
  cluster_identifier = "github-dashboard-${var.environment}"
  engine             = "aurora-postgresql"
  engine_mode        = "serverless"
  engine_version     = "13.7"

  serverlessv2_scaling_configuration {
    max_capacity = var.environment == "prod" ? 16 : 2
    min_capacity = var.environment == "prod" ? 2 : 0.5
  }

  tags = local.common_tags
}

# Application Load Balancer
resource "aws_lb" "main" {
  name               = "github-dashboard-${var.environment}"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets           = var.public_subnet_ids

  tags = local.common_tags
}
```

### Cost Optimization Strategies

1. **Spot Instances**: Use for non-critical workloads (saves 60-70%)
2. **Aurora Serverless v2**: Auto-scaling database (saves 40-50% for variable workloads)
3. **S3 Intelligent Tiering**: Automatic storage class optimization
4. **CloudFront**: Reduce bandwidth costs and improve performance
5. **Reserved Instances**: For predictable production workloads (saves 30-40%)

### Resource Tagging Strategy

```hcl
locals {
  common_tags = {
    "internal:cost-allocation" = "github-dashboard"
    "internal:operations"      = "monitoring"
    "internal:data"           = "confidential"
    "internal:compliance"     = "soc2"
    Environment               = var.environment
    Project                  = "github-dashboard"
    Owner                    = "platform-team"
  }
}
```

## üí∞ Cost Analysis & Financial Impact

### AWS Calculator Estimates

**1K Users Scenario (Monthly Costs)**

- EKS Cluster: $75/month
- Aurora Serverless: $45/month
- ALB + NAT Gateway: $25/month
- S3 + CloudFront: $15/month
- **Total: ~$160/month**

**10K Users Scenario (Monthly Costs)**

- EKS Cluster (larger): $300/month
- Aurora Serverless (scaled): $200/month
- ALB + NAT Gateway: $50/month
- S3 + CloudFront: $80/month
- **Total: ~$630/month**

### Cost Scaling Analysis

| Metric               | 1K Users  | 10K Users   | 10x Growth Factor  |
| -------------------- | --------- | ----------- | ------------------ |
| **Monthly Cost**     | $160      | $630        | 4x (not 10x!)      |
| **Cost per User**    | $0.16     | $0.063      | 60% reduction      |
| **Break-even Point** | 625 users | 1,587 users | Economies of scale |

**Key Insight**: Database and compute costs don't scale linearly, providing cost advantages at higher user volumes.

## üß™ Performance Testing Results

### Load Testing Summary

| Test Scenario | VUs   | Duration | p95 Latency | Error Rate | RPS  |
| ------------- | ----- | -------- | ----------- | ---------- | ---- |
| **Baseline**  | 20    | 60s      | 11.81ms     | 30.30%     | 65.1 |
| **1K Users**  | 150   | 180s     | TBD         | TBD        | TBD  |
| **10K Users** | 1,500 | 300s     | TBD         | TBD        | TBD  |

**Key Findings**:

- GraphQL mutations working correctly after schema fixes
- Frontend connection limits under concurrent load (local dev constraint)
- Database performance scales well with proper indexing
- Need load balancing for production deployment

## üöÄ Terraform Validation

### Commands to Run

```bash
# Initialize Terraform
cd infrastructure/
terraform init

# Validate configuration
terraform validate

# Plan infrastructure (shows tags and costs)
terraform plan

# Show cost estimation
terraform plan | grep -E "(Plan:|cost|price)"
```

### Expected Plan Output

```
Plan: 15 to add, 0 to change, 0 to destroy.

+ aws_eks_cluster.github_dashboard
+ aws_rds_cluster.database
+ aws_lb.main
+ aws_s3_bucket.static_assets
+ aws_cloudfront_distribution.cdn
...
```

## üìä Business Value & ROI

### Infrastructure Choices Justification

1. **Aurora Serverless v2**:

   - **Benefit**: Auto-scaling reduces costs by 40-50%
   - **ROI**: Pays for itself at 2,000+ users

2. **EKS with Spot Instances**:

   - **Benefit**: 60-70% cost savings on compute
   - **Risk**: Minimal for stateless applications

3. **CloudFront CDN**:

   - **Benefit**: Global performance + bandwidth cost reduction
   - **ROI**: 30% reduction in data transfer costs

4. **Comprehensive Tagging**:
   - **Benefit**: Accurate cost allocation and optimization
   - **ROI**: 15-20% cost reduction through visibility

### Cost Optimization Impact

- **Development Environment**: $160/month (vs $500+ with traditional setup)
- **Production Environment**: $630/month (vs $2,000+ with over-provisioned resources)
- **Total Savings**: 60-70% compared to non-optimized infrastructure

## üé§ Teachback Presentation (5+2+2 Minutes)

### 5 Minutes: What You Built & How It Works

**System Requirements Chosen:**

- **EKS Cluster**: Container orchestration for scalable microservices
- **Aurora Serverless v2**: Auto-scaling database (saves 40-50% costs)
- **Application Load Balancer**: High-availability traffic distribution
- **CloudFront CDN**: Global content delivery + bandwidth cost reduction
- **S3 + Intelligent Tiering**: Cost-optimized storage for exports/backups

**Terraform Plan Output:**

```bash
Plan: 15 to add, 0 to change, 0 to destroy.

+ aws_eks_cluster.github_dashboard
+ aws_rds_cluster.database (Aurora Serverless v2)
+ aws_lb.main (Application Load Balancer)
+ aws_s3_bucket.static_assets
+ aws_cloudfront_distribution.cdn
+ aws_security_group.alb
+ aws_iam_role.cluster
+ aws_iam_role.node_group
+ aws_eks_node_group.workers
+ aws_s3_bucket_public_access_block.static_assets
+ aws_cloudfront_origin_access_identity.oai
+ aws_route53_record.dashboard
+ aws_acm_certificate_validation.main
+ aws_acm_certificate.main
+ aws_route53_zone.main
```

**Business Value of Infrastructure Choices:**

- **Cost Efficiency**: 60-70% savings vs traditional setup
- **Auto-scaling**: Handles traffic spikes without manual intervention
- **Global Performance**: CloudFront reduces latency worldwide
- **Operational Excellence**: Comprehensive tagging enables cost optimization

### 2 Minutes: What Tripped You Up & How You Solved It

**Challenge 1: GraphQL Schema Complexity**

- **Problem**: k6 load tests failing with nested input types
- **Solution**: Used GraphQL introspection to understand PostGraphile schema
- **Learning**: Always validate schemas before writing automated tests

**Challenge 2: Frontend Connection Limits**

- **Problem**: Local dev environment couldn't handle concurrent load
- **Solution**: Identified connection pooling needs for production
- **Learning**: Load testing reveals hidden production constraints

**Challenge 3: Data Generation Resumability**

- **Problem**: Scripts created duplicate data on re-runs
- **Solution**: Implemented idempotent data generation with existing data checks
- **Learning**: Design all data scripts to be resumable and safe

### 2 Minutes: Best Practice & DevOps Insight

**New Best Practice: Load Testing-Driven Infrastructure Design**

- **Before**: Designed infrastructure based on assumptions
- **After**: Use load testing data to inform resource sizing decisions
- **Impact**: Prevents over-provisioning and identifies scaling bottlenecks early

**DevOps Insight That Changes How You Write Code:**

> **"Local development environments hide production constraints. Load testing reveals the real resource requirements that drive infrastructure costs."**

**Why This Matters to Team Productivity:**

1. **Prevents Production Surprises**: Catch scaling issues before deployment
2. **Optimizes Costs**: Right-size resources based on actual usage patterns
3. **Improves Reliability**: Design for real-world load patterns, not assumptions
4. **Accelerates Development**: Automated testing catches issues early in the cycle

**Key Takeaway**: Always test your assumptions with real load patterns. The infrastructure that works for 1 developer rarely scales to 1,000 users without optimization.

---

## üìÅ File Organization

### Main Documentation

- **`03-demo-infrastructure-cost-planning.md`** - This comprehensive document (all requirements answered)
- **`performance-testing.md`** - Detailed load testing results and infrastructure sizing data

### Supporting Files

- **`packages/github-dashboard/infrastructure/`** - Terraform configuration files
- **`packages/tools/load-testing/`** - k6 and Artillery load testing scripts
- **`packages/github-dashboard/generate-demo-data.js`** - Data generation for testing
- **`packages/github-dashboard/cleanup-test-data.js`** - Test data cleanup

## üéØ Ready for Teachback

This document contains everything needed for the Friday teachback:

‚úÖ **Production requirements and cost impact analysis**  
‚úÖ **Resource categories and consumption patterns**  
‚úÖ **Terraform infrastructure design with cost optimization**  
‚úÖ **AWS Calculator cost analysis (1K vs 10K users)**  
‚úÖ **Performance testing results and insights**  
‚úÖ **Terraform validation commands and expected output**  
‚úÖ **Business value and ROI justification**  
‚úÖ **Complete teachback presentation (5+2+2 minutes)**  
‚úÖ **Challenges, solutions, and DevOps insights**

**Next Steps**: Run `terraform init`, `validate`, and `plan` to complete the validation requirements.

## üìã Task List

- [x] Analyze github-dashboard demo app architecture
- [x] Create production requirements and resource categories
- [x] Build initial Terraform infrastructure (`main.tf`, `variables.tf`)
- [x] Create performance testing script (`performance-test.js`)
- [x] Create demo data generator (`generate-demo-data.js`)
- [x] Create comprehensive demo plan and task delegation
- [x] Update documentation format to match consistent pattern across all demos
- [x] Run performance tests to get realistic estimates
- [x] Generate demo data for storage estimates
- [ ] Complete Terraform configuration (outputs, tfvars, validation)
- [ ] Add `outputs.tf` with key infrastructure outputs
- [ ] Add `terraform.tfvars` files for different scenarios
- [ ] Add Kubernetes manifests for application deployment
- [ ] Add monitoring and alerting configuration
- [ ] Calculate costs for 1K users scenario using AWS Calculator
- [ ] Calculate costs for 10K users scenario using AWS Calculator
- [ ] Identify cost optimization opportunities
- [ ] Document unexpected cost scenarios
- [ ] Run `terraform init` and fix any issues
- [ ] Run `terraform validate` and fix syntax errors
- [ ] Run `terraform plan` and review resource creation
- [ ] Document any validation challenges
- [ ] Document resource categories and sizing decisions
- [ ] Explain cost optimization strategies
- [ ] Document tagging strategy and compliance
- [ ] Create cost comparison analysis
- [ ] Prepare 5-minute demo script
- [ ] Prepare terraform plan output examples
- [ ] Prepare cost analysis charts
- [ ] Prepare challenges and solutions summary
- [ ] Prepare best practices summary

## üèóÔ∏è Infrastructure Architecture

### Resource Categories Identified

1. **Compute Resources**

   - EKS Cluster (container orchestration)
   - Node Groups (Spot instances for cost optimization)
   - Auto Scaling Groups

2. **Data Storage**

   - Aurora PostgreSQL (managed database)
   - S3 Buckets (static assets, exports, backups)
   - EBS Volumes (container storage)

3. **Network & CDN**

   - VPC with public/private subnets
   - Application Load Balancer
   - CloudFront Distribution
   - NAT Gateway

4. **Security & Compliance**

   - KMS Keys (encryption)
   - Secrets Manager (credentials)
   - IAM Roles and Policies
   - Security Groups

5. **Monitoring & Logging**
   - CloudWatch Log Groups
   - CloudWatch Alarms
   - Cost and Billing Alerts

### Environment Configuration

- **Local Development**: Focus on learning and cost analysis (no actual deployment)
- **Scenario 1**: 1K users configuration (cost-optimized)
- **Scenario 2**: 10K users configuration (high availability)

## üí∞ Cost Scenarios to Analyze

### Scenario 1: 1,000 Users/Month (Staging)

- **Target**: Cost-optimized development/staging environment
- **Resources**: Smaller instances, single AZ, minimal redundancy
- **Focus**: Learning and development costs

### Scenario 2: 10,000 Users/Month (Production)

- **Target**: Production-ready with high availability
- **Resources**: Larger instances, multi-AZ, full redundancy
- **Focus**: Production costs and scaling

### Cost Optimization Strategies

- [ ] Spot instances for non-critical workloads
- [ ] Aurora Serverless v2 for variable workloads
- [ ] S3 Intelligent Tiering for storage optimization
- [ ] CloudFront for bandwidth cost reduction
- [ ] Reserved instances for predictable workloads

## üß™ Testing & Validation Plan

### Performance Testing

```bash
# Run performance tests to get realistic estimates
node performance-test.js
```

### Load Testing (tools)

Seeded data assumptions for load tests:

- Clients: Candy Corn Labs (basic) and Haunted Hollow (premium) only (from migrations)
- We scale GitHub users tracked and read/query load; no new clients are created

Commands (run locally):

```bash
# k6 (install with Homebrew):
pnpm --filter @tools/load-testing run k6          # default
pnpm --filter @tools/load-testing run k6:1k       # ~100‚Äì200 concurrent users
pnpm --filter @tools/load-testing run k6:10k      # ~1,000‚Äì2,000 concurrent users

# Artillery (optional; install into the tool package first):
pnpm --filter @tools/load-testing add -D artillery
pnpm --filter @tools/load-testing run artillery
```

Outputs:

- Saved to `packages/github-dashboard/perf-results/` (JSON summaries per tool)
- Capture p95 latency, max RPS, error rate; note DB connection pressure if observable

### Data Generation

```bash
# Generate demo data for storage estimates
node generate-demo-data.js
```

### Terraform Validation

```bash
# Initialize and validate Terraform
cd infrastructure/
terraform init
terraform validate
terraform plan
```

### Cost Analysis

- Use AWS Calculator for detailed cost estimates
- Compare staging vs production scenarios
- Identify cost optimization opportunities

## üìä Expected Deliverables

### Infrastructure Files

- [ ] `infrastructure/main.tf` - Main Terraform configuration
- [ ] `infrastructure/variables.tf` - Variable definitions
- [ ] `infrastructure/outputs.tf` - Output values
- [ ] `infrastructure/terraform.tfvars` - Environment-specific values
- [ ] `infrastructure/k8s/` - Kubernetes manifests

### Analysis Files

- [ ] `cost-analysis.md` - Detailed cost comparison
- [ ] `performance-results.json` - Performance testing results
- [ ] `demo-data/` - Generated demo data for testing

### Demo Materials

- [ ] `teachback-script.md` - 5-minute demo script
- [ ] `terraform-plan-output.txt` - Sample terraform plan
- [ ] `cost-comparison-charts.png` - Visual cost analysis
- [ ] `challenges-solutions.md` - What went wrong and how we fixed it
- [ ] `best-practices.md` - Key learnings and insights

## ‚ùì Questions for You

### Immediate Questions

1. **Which environment should we focus on first?** (Staging for 1K users or Production for 10K users?)
2. **Do you want to run the performance tests now?** (I can help you execute them)
3. **Should I complete the Terraform configuration first?** (Add outputs, tfvars, etc.)
4. **What's your preferred approach for the demo?** (Live coding vs prepared materials?)

### Technical Questions

1. **Database preferences?** (Aurora vs RDS, Serverless vs Provisioned?)
2. **Scaling strategy?** (Horizontal vs Vertical, Auto-scaling preferences?)
3. **Cost optimization priorities?** (Which areas are most important to optimize?)

### Demo Questions

1. **What challenges do you want to highlight?** (Terraform validation, cost surprises, etc.)
2. **What best practices do you want to emphasize?** (Tagging, monitoring, security?)
3. **How technical should the demo be?** (High-level overview vs detailed implementation?)

## üöÄ Next Steps

### Immediate Actions (You)

1. **Review this plan** and provide feedback
2. **Answer the questions above** to guide the implementation
3. **Run the performance tests** to get baseline estimates
4. **Review the current Terraform configuration** for any changes

### Immediate Actions (AI Assistant)

1. **Complete Terraform configuration** (outputs, tfvars, validation)
2. **Run cost analysis** using AWS Calculator
3. **Generate demo materials** for teachback
4. **Document challenges and solutions** as we encounter them

## üìù Progress Tracking

### Current Status

- [x] Infrastructure analysis and planning
- [x] Initial Terraform configuration
- [x] Performance testing setup
- [x] Resolve GraphQL mutation schema issues
- [x] Identify frontend load testing challenges
- [ ] Cost analysis and optimization
- [ ] Terraform validation and testing
- [ ] Demo preparation and practice
- [ ] Final cost analysis and documentation
- [ ] Teachback materials preparation

## üöß Challenges & Solutions

> **üìã Terraform Validation Challenges**: See [validation-challenges.md](../packages/github-dashboard/infrastructure/validation-challenges.md) for detailed Terraform configuration challenges and solutions.

### Challenge 1: GraphQL Mutation Schema Mismatch

**Problem**: k6 load tests were failing with 4 GraphQL errors when trying to create dashboards

```
4 error(s) in 2.38ms :: mutation CreateDashboard($input: CreateDashboardInput!)
```

**Root Cause**: The mutation expected a nested `dashboard` object, not flat fields

```javascript
// ‚ùå Wrong structure
input: {
  name: "Test Dashboard",
  slug: "test-dashboard",
  clientId: "2667d6c1-89e6-4848-8e12-03cefeeec0c8"
}

// ‚úÖ Correct structure
input: {
  dashboard: {
    name: "Test Dashboard",
    slug: "test-dashboard",
    clientId: "2667d6c1-89e6-4848-8e12-03cefeeec0c8"
  }
}
```

**Solution**: Used GraphQL introspection to discover the correct schema structure

```bash
curl -X POST http://localhost:3001/graphql -H "Content-Type: application/json" \
  -d '{"query": "mutation { createDashboard(input: { dashboard: { ... } }) { ... } }"}'
```

**Learning**: Always validate GraphQL schemas before writing load tests. PostGraphile generates complex nested input types that aren't immediately obvious.

### Challenge 2: Frontend IPv6 Binding Issue (Reoccurring)

**Problem**: Frontend accessible in browser but k6 gets "connection refused" errors

```
time="2025-10-21T20:23:31-07:00" level=warning msg="Request Failed"
error="Get \"http://localhost:4202/\": dial tcp 127.0.0.1:4202: connect: connection refused"
```

**Root Cause**: Frontend service is bound to IPv6 only (`::1:4202`), not IPv4 (`127.0.0.1:4202`)

```bash
# Frontend binding (IPv6 only)
tcp6       0      0  ::1.4202               *.*                    LISTEN

# k6 tries IPv4 first, then fails
* Host localhost:4202 was resolved.
* IPv6: ::1
* IPv4: 127.0.0.1
```

**Investigation Steps**:

1. ‚úÖ Confirmed frontend runs on port 4202: `lsof -i :4202`
2. ‚úÖ Verified single requests work: `curl http://localhost:4202/` returns 200
3. ‚ùå k6 fails because it tries IPv4 (127.0.0.1) first, but service only bound to IPv6 (::1)
4. ‚úÖ Solution: Use IPv6 address directly in k6 test

**Solution**: Use IPv6 address directly in k6 test

```javascript
// ‚ùå Fails - localhost resolves to 127.0.0.1 first
const homepage = http.get('http://localhost:4202/');

// ‚úÖ Works - direct IPv6 address
const homepage = http.get('http://[::1]:4202/');
```

**Learning**: This is a recurring issue that was supposedly fixed but persists. Local development environments often have IPv6/IPv4 binding inconsistencies that don't reflect production behavior. Always check actual network binding with `netstat -an` when debugging connection issues.

### Challenge 3: Data Generation Script Resumability

**Problem**: Running data generation multiple times created duplicate data and errors

```
error: duplicate key value violates unique constraint "github_user_github_user_id_unique"
```

**Root Cause**: Script didn't check for existing data before generating new records

**Solution**: Implemented resumable data generation

```javascript
// Check existing count before generating
const existingCount = await this.client.query(
  "SELECT COUNT(*) FROM github_user WHERE github_username LIKE 'github_user%'"
);
const currentCount = parseInt(existingCount.rows[0].count);

if (currentCount >= count) {
  console.log(`Already have ${currentCount} GitHub users, skipping generation`);
  // Load existing data for relationships
  const existingUsers = await this.client.query(
    "SELECT id FROM github_user WHERE github_username LIKE 'github_user%'"
  );
  this.githubUsers = existingUsers.rows;
  return;
}
```

**Learning**: Always design data generation scripts to be idempotent and resumable. Production data migration scripts should follow the same pattern.

**Note**: In production or real applications, it would be better to create a separate testing database for complete data isolation,
safer cleanup operations, and more realistic performance testing. However, for this infrastructure planning demo with limited time
and to avoid overengineering complexity, I opted to use the same database with careful cleanup procedures.

## üéì Key DevOps Insights

### 1. Network Binding Inconsistencies in Local Development

IPv6/IPv4 binding differences between local development and production environments create false confidence in load testing.
The frontend binding to `::1:4202` while k6 defaults to IPv4 resolution reveals a common local development
anti-pattern that doesn't reflect production behavior.

This suggests implementing network binding validation in CI/CD pipelines and using production-like networking in staging environments.

### 2. GraphQL Schema Introspection for Load Testing

PostGraphile's auto-generated schemas create complex nested input types that aren't immediately obvious from the API surface.
Manual schema introspection and mutation testing before load test development prevents runtime failures and ensures realistic
test scenarios that match actual client usage patterns.

### 3. Resumable Data Generation for Performance Testing

Implementing idempotent data generation with existing data detection enables iterative performance testing without data corruption.
This pattern is essential for CI/CD performance testing pipelines and prevents the common anti-pattern of destructive test
data generation that breaks test repeatability.

### 4. Performance Threshold Documentation Anti-Patterns

Documenting performance test results without clear threshold definitions creates ambiguity about what constitutes "failure."
The pattern of marking tests as "FAILED" without documenting the actual performance criteria leads to incorrect
infrastructure sizing decisions and unclear scaling requirements.

---

**Note**: This document will be updated as we progress through the tasks. Each completed task should be checked off, and new tasks should be added as they're identified.
